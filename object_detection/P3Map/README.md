# P3Map


## Preprocessing operations

The following operations are performed in the image segmentation pipeline (found in `image_segmentation/pytorch/data_loading/pytorch_loader.py`):

1. LoadImage
2. RandBalancedCrop
3. RandFlip
4. Cast
5. RandomBrightnessAugmentation
6. GaussianNoise

Note: Below configurations from parser defaults values of the benchmark for `RandBalancedCrop`

```python
input_shape = [128, 128, 128]
oversampling = 0.4
config = {"patch_size": input_shape, "oversampling": oversampling,}
# Since, some operations are performed on the basis of a probability, but for the sake of mapping we set it to 1. 
```

## Steps to get mapping via P3Map

```bash
conda activate instrumentation_env
# Follow instructions in image_segmentation/itt-python/README.md for installing
# Be outside P3Map directory and run below command
bash P3Map/P3Map.sh
# Run the `image_segmentation/pytorch/P3Map/logsToMapping.ipynb`
# Output mapping is stored in `image_segmentation/pytorch/P3Map/mapping_funcs.json`
```

## HW profiler data collection

1. 
    ```bash
    vtune -collect memory-access -data-limit 0 -result-dir ./tmp -- bash metal_run_and_time.sh 1 ./p3torch_logs/vtune_included
    # Use below command and open browser on the link generated by it
    vtune-backend --web-port 8080 --data-directory ./tmp
    ```

    Below steps are manual
2. Navigate to Microarchitecture Exploration tab
3. Perform grouping by `Source Function / Function / Call Stack`
4. Select all cells and paste in a file as `uarch.csv`


## Finding large element from the `kits19` dataset

```bash
find ../pytorch/datasets/coco/train2017 -type f -printf "%s\t%p\n" | sort -n | tail -1
```
Above should yield `coco/train2017/000000479400.jpg`. We copy the corresponding label to it `case_00165_y.npy`.

## Meta information for COCO dataset

```python
# get path of the largest image (1.9 MB) in the dataset is ../pytorch/datasets/coco/train2017/479400.jpg
# id -> 96601
# dataset.ids[id] -> 479400
# file_name = dataset.coco.loadImgs(id)[0]["file_name"] -> 000000479400.jpg
# annotation_id = dataset.coco.getAnnIds(id) -> [1039016, 1645897, 1646645]
# annotation = dataset.coco.loadAnns(annotation_id) -> [{'segmentation': [[66.16, 493.3, 102.11, 542.2, 161.08, 598.29, 217.17, 602.61, 268.94, 568.09, 304.9, 520.63, 320.72, 453.03, 313.53, 442.97, 296.27, 421.39, 263.19, 395.51, 189.84, 365.3, 140.94, 350.92, 79.1, 356.67, 38.83, 373.93, 44.58, 432.9, 61.84, 499.06]], 'area': 49810.38265, 'iscrowd': 0, 'image_id': 479400, 'bbox': [38.83, 350.92, 281.89, 251.69], 'category_id': 51, 'id': 1039016}, {'segmentation': [[371.8, 326.08, 356.99, 324.3, 344.55, 321.64, 339.52, 318.97, 337.74, 318.08, 336.85, 308.9, 338.63, 306.24, 343.96, 304.76, 365.58, 303.28, 380.09, 303.87, 392.53, 305.35, 405.26, 307.42, 408.81, 310.38, 408.81, 321.04, 408.22, 322.82, 400.52, 324.6, 384.83, 325.49, 376.24, 325.78]], 'area': 1377.9213500000003, 'iscrowd': 0, 'image_id': 479400, 'bbox': [336.85, 303.28, 71.96, 22.8], 'category_id': 81, 'id': 1645897}, {'segmentation': [[240.74, 294.68, 242.3, 303.08, 247.19, 305.62, 263.4, 307.57, 274.34, 306.79, 287.63, 305.03, 294.27, 303.86, 295.25, 301.32, 296.03, 294.48, 287.04, 291.16, 278.05, 290.97, 266.14, 290.19, 254.42, 291.36, 246.21, 293.12]], 'area': 776.196999999999, 'iscrowd': 0, 'image_id': 479400, 'bbox': [240.74, 290.19, 55.29, 17.38], 'category_id': 81, 'id': 1646645}]
# {"license": 1,"file_name": "000000479400.jpg","coco_url": "http://images.cocodataset.org/train2017/000000479400.jpg","height": 640,"width": 434,"date_captured": "2013-11-15 02:12:20","flickr_url": "http://farm9.staticflickr.com/8516/8472642889_827b8258d1_z.jpg","id": 479400}
```